{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PVhqKKNT3a-JQfFu4BHs21O4EmtirzLc",
      "authorship_tag": "ABX9TyN15Su9Wqy37OcyjDSIRdTO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dautonbh/3-Mini-Python-Projects/blob/main/Duplicados_android.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "c_R9HQP7ewiS",
        "outputId": "dadbca02-ee5f-40ce-adfc-d3f53aeddb6e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 13)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    for root, dirs, files in os.walk(caminho_base):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import mimetypes\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import fitz  # PyMuPDF para manipular PDFs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Função para listar arquivos e pastas por tipo\n",
        "def listar_arquivos_e_pastas(caminho_base):\n",
        "     '/Cartão SD/Docs/Pasta 1.2'\n",
        "     arquivos_por_tipo = {}\n",
        "\n",
        "    for root, dirs, files in os.walk(caminho_base):\n",
        "        for nome_arquivo in files:\n",
        "            caminho_completo = os.path.join(root, nome_arquivo)\n",
        "            tipo_arquivo, _ = mimetypes.guess_type(caminho_completo)\n",
        "\n",
        "            if tipo_arquivo not in arquivos_por_tipo:\n",
        "                arquivos_por_tipo[tipo_arquivo] = []\n",
        "\n",
        "            arquivos_por_tipo[tipo_arquivo].append(caminho_completo)\n",
        "\n",
        "    return arquivos_por_tipo\n",
        "\n",
        "# Função para calcular hash de um arquivo (MD5 por exemplo)\n",
        "def calcular_hash_arquivo(caminho_arquivo, algoritmo='md5'):\n",
        "    hash_algoritmo = hashlib.new(algoritmo)\n",
        "    with open(caminho_arquivo, 'rb') as f:\n",
        "        while chunk := f.read(8192):\n",
        "            hash_algoritmo.update(chunk)\n",
        "    return hash_algoritmo.hexdigest()\n",
        "\n",
        "# Função para identificar duplicados em uma pasta\n",
        "def identificar_arquivos_duplicados(caminho_base):\n",
        "    arquivos_info = []\n",
        "\n",
        "    for root, dirs, files in os.walk(caminho_base):\n",
        "        for nome_arquivo in files:\n",
        "            caminho_completo = os.path.join(root, nome_arquivo)\n",
        "            tamanho_arquivo = os.path.getsize(caminho_completo)\n",
        "            hash_arquivo = calcular_hash_arquivo(caminho_completo)\n",
        "\n",
        "            arquivos_info.append((nome_arquivo, tamanho_arquivo, hash_arquivo, caminho_completo))\n",
        "\n",
        "    arquivos_df = pd.DataFrame(arquivos_info, columns=['Nome', 'Tamanho', 'Hash', 'Caminho'])\n",
        "\n",
        "    # Identificar duplicados com base no Hash\n",
        "    duplicados = arquivos_df[arquivos_df.duplicated(subset='Hash', keep=False)]\n",
        "\n",
        "    return duplicados\n",
        "\n",
        "# Função para contar arquivos de um tipo específico (ex: PDF)\n",
        "def contar_arquivos_por_tipo(caminho_base, tipo_alvo='.pdf'):\n",
        "    arquivos_pdf = []\n",
        "\n",
        "    for root, dirs, files in os.walk(caminho_base):\n",
        "        for nome_arquivo in files:\n",
        "            if nome_arquivo.lower().endswith(tipo_alvo):\n",
        "                caminho_completo = os.path.join(root, nome_arquivo)\n",
        "                arquivos_pdf.append(caminho_completo)\n",
        "\n",
        "    return arquivos_pdf\n",
        "\n",
        "# Função para salvar lista de arquivos em CSV\n",
        "def salvar_arquivos_csv(arquivos, caminho_csv):\n",
        "    df = pd.DataFrame(arquivos, columns=['Caminho'])\n",
        "    df['Número'] = range(1, len(arquivos) + 1)\n",
        "    df.to_csv(caminho_csv, index=False)\n",
        "    return df\n",
        "\n",
        "# Função para visualizar prévia da primeira página de arquivos PDF duplicados\n",
        "def visualizar_arquivos_duplicados(arquivos):\n",
        "    for arquivo in arquivos:\n",
        "        try:\n",
        "            # Abre o PDF e extrai a primeira página\n",
        "            doc = fitz.open(arquivo)\n",
        "            pagina = doc.load_page(0)\n",
        "            imagem = pagina.get_pixmap()\n",
        "            plt.imshow(imagem.get_pil_image())\n",
        "            plt.title(f\"Prévia do arquivo: {os.path.basename(arquivo)}\")\n",
        "            plt.show()\n",
        "            doc.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar {arquivo}: {e}\")\n",
        "\n",
        "# Exemplo de execução\n",
        "# Aqui você insere o caminho da pasta no Android\n",
        "caminho_base = '/storage/emulated/0/Download'  # Insira o caminho da pasta aqui\n",
        "\n",
        "# Exemplo de listar arquivos\n",
        "arquivos_enumerados = listar_arquivos_e_pastas(caminho_base)\n",
        "print(\"Arquivos por tipo:\")\n",
        "for tipo, arquivos in arquivos_enumerados.items():\n",
        "    print(f\"Tipo: {tipo}, Total: {len(arquivos)}\")\n",
        "    for arquivo in arquivos:\n",
        "        print(f\"  - {arquivo}\")\n",
        "\n",
        "# Exemplo de identificar arquivos import osimport mimetypesimport pandas as pdimport hashlibimport fitz  # PyMuPDF para manipular PDFsimport matplotlib.pyplot as plt\n",
        "# Função para listar arquivos e pastas por tipodef listar_arquivos_e_pastas(caminho_base): '/Cartão SD/Docs/Pasta 1.2'    arquivos_por_tipo = {}\n",
        "    for root, dirs, files in os.walk(caminho_base):        for nome_arquivo in files:            caminho_completo = os.path.join(root, nome_arquivo)            tipo_arquivo, _ = mimetypes.guess_type(caminho_completo)                        if tipo_arquivo not in arquivos_por_tipo:                arquivos_por_tipo[tipo_arquivo] = []                        arquivos_por_tipo[tipo_arquivo].append(caminho_completo)\n",
        "    return arquivos_por_tipo\n",
        "# Função para calcular hash de um arquivo (MD5 por exemplo)def calcular_hash_arquivo(caminho_arquivo, algoritmo='md5'):    hash_algoritmo = hashlib.new(algoritmo)    with open(caminho_arquivo, 'rb') as f:        while chunk := f.read(8192):            hash_algoritmo.update(chunk)    return hash_algoritmo.hexdigest()\n",
        "# Função para identificar duplicados em uma pastadef identificar_arquivos_duplicados(caminho_base):    arquivos_info = []        for root, dirs, files in os.walk(caminho_base):        for nome_arquivo in files:            caminho_completo = os.path.join(root, nome_arquivo)            tamanho_arquivo = os.path.getsize(caminho_completo)            hash_arquivo = calcular_hash_arquivo(caminho_completo)                        arquivos_info.append((nome_arquivo, tamanho_arquivo, hash_arquivo, caminho_completo))        arquivos_df = pd.DataFrame(arquivos_info, columns=['Nome', 'Tamanho', 'Hash', 'Caminho'])        # Identificar duplicados com base no Hash    duplicados = arquivos_df[arquivos_df.duplicated(subset='Hash', keep=False)]        return duplicados\n",
        "# Função para contar arquivos de um tipo específico (ex: PDF)def contar_arquivos_por_tipo(caminho_base, tipo_alvo='.pdf'):    arquivos_pdf = []        for root, dirs, files in os.walk(caminho_base):        for nome_arquivo in files:            if nome_arquivo.lower().endswith(tipo_alvo):                caminho_completo = os.path.join(root, nome_arquivo)                arquivos_pdf.append(caminho_completo)        return arquivos_pdf\n",
        "# Função para salvar lista de arquivos em CSVdef salvar_arquivos_csv(arquivos, caminho_csv):    df = pd.DataFrame(arquivos, columns=['Caminho'])    df['Número'] = range(1, len(arquivos) + 1)    df.to_csv(caminho_csv, index=False)    return df\n",
        "# Função para visualizar prévia da primeira página de arquivos PDF duplicadosdef visualizar_arquivos_duplicados(arquivos):    for arquivo in arquivos:        try:            # Abre o PDF e extrai a primeira página            doc = fitz.open(arquivo)            pagina = doc.load_page(0)            imagem = pagina.get_pixmap()            plt.imshow(imagem.get_pil_image())            plt.title(f\"Prévia do arquivo: {os.path.basename(arquivo)}\")            plt.show()            doc.close()        except Exception as e:            print(f\"Erro ao processar {arquivo}: {e}\")\n",
        "# Exemplo de execução# Aqui você insere o caminho da pasta no Androidcaminho_base = '/storage/emulated/0/Download'  # Insira o caminho da pasta aqui\n",
        "# Exemplo de listar arquivosarquivos_enumerados = listar_arquivos_e_pastas(caminho_base)print(\"Arquivos por tipo:\")for tipo, arquivos in arquivos_enumerados.items():    print(f\"Tipo: {tipo}, Total: {len(arquivos)}\")    for arquivo in arquivos:        print(f\"  - {arquivo}\")\n",
        "# Exemplo de identificar arquivos duplicadosarquivos_duplicados = identificar_arquivos_duplicados(caminho_base)print(\"Arquivos duplicados encontrados:\")print(arquivos_duplicados)\n",
        "# Exemplo de contar e salvar PDFsarquivos_pdf = contar_arquivos_por_tipo(caminho_base, '.pdf')caminho_csv = 'arquivos_pdf.csv'df_arquivos_pdf = salvar_arquivos_csv(arquivos_pdf, caminho_csv)\n",
        "import osimport mimetypesimport pandas as pdimport hashlibimport fitz  # PyMuPDF para manipular PDFsimport matplotlib.pyplot as plt\n",
        "# Função para listar arquivos e pastas por tipodef listar_arquivos_e_pastas(caminho_base): '/Cartão SD/Docs/Pasta 1.2'    arquivos_por_tipo = {}\n",
        "    for root, dirs, files in os.walk(caminho_base):        for nome_arquivo in files:            caminho_completo = os.path.join(root, nome_arquivo)            tipo_arquivo, _ = mimetypes.guess_type(caminho_completo)                        if tipo_arquivo not in arquivos_por_tipo:                arquivos_por_tipo[tipo_arquivo] = []                        arquivos_por_tipo[tipo_arquivo].append(caminho_completo)\n",
        "    return arquivos_por_tipo\n",
        "# Função para calcular hash de um arquivo (MD5 por exemplo)def calcular_hash_arquivo(caminho_arquivo, algoritmo='md5'):    hash_algoritmo = hashlib.new(algoritmo)    with open(caminho_arquivo, 'rb') as f:        while chunk := f.read(8192):            hash_algoritmo.update(chunk)    return hash_algoritmo.hexdigest()\n",
        "# Função para identificar duplicados em uma pastadef identificar_arquivos_duplicados(caminho_base):    arquivos_info = []        for root, dirs, files in os.walk(caminho_base):        for nome_arquivo in files:            caminho_completo = os.path.join(root, nome_arquivo)            tamanho_arquivo = os.path.getsize(caminho_completo)            hash_arquivo = calcular_hash_arquivo(caminho_completo)                        arquivos_info.append((nome_arquivo, tamanho_arquivo, hash_arquivo, caminho_completo))        arquivos_df = pd.DataFrame(arquivos_info, columns=['Nome', 'Tamanho', 'Hash', 'Caminho'])        # Identificar duplicados com base no Hash    duplicados = arquivos_df[arquivos_df.duplicated(subset='Hash', keep=False)]        return duplicados\n",
        "# Função para contar arquivos de um tipo específico (ex: PDF)def contar_arquivos_por_tipo(caminho_base, tipo_alvo='.pdf'):    arquivos_pdf = []        for root, dirs, files in os.walk(caminho_base):        for nome_arquivo in files:            if nome_arquivo.lower().endswith(tipo_alvo):                caminho_completo = os.path.join(root, nome_arquivo)                arquivos_pdf.append(caminho_completo)        return arquivos_pdf\n",
        "# Função para salvar lista de arquivos em CSVdef salvar_arquivos_csv(arquivos, caminho_csv):    df = pd.DataFrame(arquivos, columns=['Caminho'])    df['Número'] = range(1, len(arquivos) + 1)    df.to_csv(caminho_csv, index=False)    return df\n",
        "# Função para visualizar prévia da primeira página de arquivos PDF duplicadosdef visualizar_arquivos_duplicados(arquivos):    for arquivo in arquivos:        try:            # Abre o PDF e extrai a primeira página            doc = fitz.open(arquivo)            pagina = doc.load_page(0)            imagem = pagina.get_pixmap()            plt.imshow(imagem.get_pil_image())            plt.title(f\"Prévia do arquivo: {os.path.basename(arquivo)}\")            plt.show()            doc.close()        except Exception as e:            print(f\"Erro ao processar {arquivo}: {e}\")\n",
        "# Exemplo de execução# Aqui você insere o caminho da pasta no Androidcaminho_base = '/storage/emulated/0/Download'  # Insira o caminho da pasta aqui\n",
        "# Exemplo de listar arquivosarquivos_enumerados = listar_arquivos_e_pastas(caminho_base)print(\"Arquivos por tipo:\")for tipo, arquivos in arquivos_enumerados.items():    print(f\"Tipo: {tipo}, Total: {len(arquivos)}\")    for arquivo in arquivos:        print(f\"  - {arquivo}\")\n",
        "# Exemplo de identificar arquivos duplicadosarquivos_duplicados = identificar_arquivos_duplicados(caminho_base)print(\"Arquivos duplicados encontrados:\")print(arquivos_duplicados)\n",
        "# Exemplo de contar e salvar PDFsarquivos_pdf = contar_arquivos_por_tipo(caminho_base, '.pdf')caminho_csv = 'arquivos_pdf.csv'df_arquivos_pdf = salvar_arquivos_csv(arquivos_pdf, caminho_csv)print(f\"Lista de PDFs salva em: {caminho_csv}\")\n",
        "# Visualizar prévias de PDFsvisualizar_arquivos_duplicados(arquivos_pdf[:5])  # Exibe prévias de 5 arquivos PDF(f\"Lista de PDFs salva em: {caminho_csv}\")\n",
        "# Visualizar prévias de PDFsvisualizar_arquivos_duplicados(arquivos_pdf[:5])  # Exibe prévias de 5 arquivos PDF\n",
        "arquivos_duplicados = identificar_arquivos_duplicados(caminho_base)\n",
        "print(\"Arquivos duplicados encontrados:\")\n",
        "print(arquivos_duplicados)\n",
        "\n",
        "# Exemplo de contar e salvar PDFs\n",
        "arquivos_pdf = contar_arquivos_por_tipo(caminho_base, '.pdf')\n",
        "caminho_csv = 'arquivos_pdf.csv'\n",
        "df_arquivos_pdf = salvar_arquivos_csv(arquivos_pdf, caminho_csv)\n",
        "print(f\"Lista de PDFs salva em: {caminho_csv}\")\n",
        "\n",
        "# Visualizar prévias de PDFs\n",
        "visualizar_arquivos_duplicados(arquivos_pdf[:5])  # Exibe prévias de 5 arquivos PDF"
      ]
    }
  ]
}